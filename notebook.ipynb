{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ec8d6a-4218-49b9-a549-0977cec82967",
   "metadata": {
    "id": "MVpsYfWg3z0B"
   },
   "source": [
    "# PW1 - Handwritten character recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d682452d-e56e-4de8-a420-4418d63790a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your name here (e.g. \"Edmond Dantès\") so I can grade your work\n",
    "your_name = \"Ismael DEMBELE\"    \n",
    "assert your_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad1905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting os-sys\n",
      "  Downloading os_sys-2.1.4-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pygubu (from os-sys)\n",
      "  Downloading pygubu-0.37-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.12/site-packages (from os-sys) (2025.2)\n",
      "Requirement already satisfied: sqlparse in /usr/local/lib/python3.12/site-packages (from os-sys) (0.5.3)\n",
      "Collecting progress (from os-sys)\n",
      "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.12/site-packages (from os-sys) (4.67.1)\n",
      "Collecting progressbar (from os-sys)\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/site-packages (from os-sys) (3.10.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from os-sys) (2.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/site-packages (from os-sys) (1.17.0)\n",
      "Collecting jupyter (from os-sys)\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/site-packages (from os-sys) (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/site-packages (from os-sys) (4.13.4)\n",
      "Collecting Eel (from os-sys)\n",
      "  Downloading eel-0.18.1.tar.gz (26 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting extract-zip (from os-sys)\n",
      "  Downloading extract_zip-1.0.0-py3-none-any.whl.metadata (403 bytes)\n",
      "INFO: pip is looking at multiple versions of os-sys to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting os-sys\n",
      "  Downloading os_sys-2.1.3-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading os_sys-2.1.2-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading os_sys-2.1.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading os_sys-2.1.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading os_sys-2.0.9-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading os_sys-2.0.8-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading os_sys-2.0.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "INFO: pip is still looking at multiple versions of os-sys to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading os_sys-2.0.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "  Downloading os_sys-2.0.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "  Downloading os_sys-2.0.4-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting webview (from os-sys)\n",
      "  Downloading webview-0.1.5.tar.gz (18 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[26 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 143, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-fwrquq2c/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 331, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-fwrquq2c/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 301, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-fwrquq2c/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 512, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-fwrquq2c/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 43, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 37, in pkgconfig\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.12/subprocess.py\", line 468, in check_output\n",
      "  \u001b[31m   \u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.12/subprocess.py\", line 573, in run\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, process.args,\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command 'pkg-config --cflags gtk+-3.0 webkit2gtk-4.0' returned non-zero exit status 127.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install os-sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8538cf7-81e0-481a-8059-be38b611aafb",
   "metadata": {
    "id": "8CcAqNjJ3z0F"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math, sys, os, torch, torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c864b86e-6e6b-4d8a-82c8-6822072a676f",
   "metadata": {
    "id": "3Wxb9pdV3z0F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: True \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using gpu: %s ' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa038da6-b812-4053-9b72-8ff97ceb3b9b",
   "metadata": {
    "id": "1Sjq8zzf3z0G"
   },
   "source": [
    "We will be training many models. Select a number of epochs to train each model. If you are using a slow machine, or if you want to restart training often and have many development iterations, we suggest `NUM_EPOCH = 2`. If you are using a fast machine, or have a GPU available, of if you are confident that you can write accurate code first try, you will get better accuracies by increasing this constant. You could be able to afford up to `NUM_EPOCH = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "137adce6-13cc-4ccc-aaf3-42230e322a9b",
   "metadata": {
    "id": "L9CF0H4O3z0G"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCH = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce850e9-ef4e-4323-af2d-be6b94e98994",
   "metadata": {
    "id": "65e20f5e"
   },
   "source": [
    "# Part A - Linear, MLP, and CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aff4bd-8b1d-4531-89d8-64ce4e2b6357",
   "metadata": {
    "id": "KSAiV2ov3z0H"
   },
   "source": [
    "## Handwritten digit recognition dataset\n",
    "\n",
    "We will use the MNIST database (Modified National Institute of Standards and Technology database). It contains tens of thousands of pictures of handwritten digits. This database was compiled in 1994, as part of the effort in the 1990s to standardize automation of sorting devices with human input, for instance sorting mail with handwritten postal codes at the post office. This is now often considered one of the first real successes of neural networks, and the first easy example on which performance of new such algorithms is tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429898a-0f57-4cdf-9aa6-7b1121ee4e53",
   "metadata": {},
   "source": [
    "Load the dataset (train and test splits) using `torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59e1c523-4b78-492a-b103-2861af8c3d89",
   "metadata": {
    "id": "Zu3hU4dQ3z0H"
   },
   "outputs": [],
   "source": [
    "root_dir = './data/MNIST/'\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=root_dir, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=root_dir, train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4832d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE=256\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77fbaba-b01f-46d0-a1d7-47c59faaf042",
   "metadata": {},
   "source": [
    "How many examples in each split? \n",
    "\n",
    "Plot the first image and label of the training set using `matplotlib`\n",
    "\n",
    "What is the input dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "083f07f4-e129-4e9b-b26e-a32fd4bdb99d",
   "metadata": {
    "id": "9fgMls5P3z0I",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples dans le train : 60000\n",
      "Nombre d'exemples dans le test  : 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nombre d'exemples dans le train : {len(train_dataset)}\")\n",
    "print(f\"Nombre d'exemples dans le test  : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc2fbd26-b017-435a-822e-ad382eabd8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(f\"Label : {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39a3f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape du tenseur image : torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape du tenseur image : {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6380c03-1427-4dea-974e-5a38621ea6c1",
   "metadata": {
    "id": "Guv5_hY63z0L"
   },
   "source": [
    "# A.1 - Linear features\n",
    "\n",
    "We start with a very simple model, linear with respect to pixel values.\n",
    "Use a `preprocess` function to downsample the image to 7x7 pixels, then flatten it and use a `torch.nn.Linear` model.\n",
    "\n",
    "The torch average-pooling function is `torch.nn.functional.avg_pool2d`, check the documentation to set the arguments properly.\n",
    "DO NOT use your implementation of average-pooling, it would take prohibitively long to train and you would not finish the practical.\n",
    "If the training takes too long, go back to the first section and lower the `NUM_EPOCH` constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb8e5d-7d84-4a59-aa5d-e942ffa22aa8",
   "metadata": {},
   "source": [
    "Again, use matplotlib to visualize an example of downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac111d5c-dfa2-44e2-9a57-f2f4c2caff2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Récupère une image\n",
    "image, label = train_dataset[0]  # image: [1, 28, 28]\n",
    "\n",
    "# Downsampling à 7x7\n",
    "downsampled = F.interpolate(image.unsqueeze(0), size=(7, 7), mode='bilinear', align_corners=False)\n",
    "\n",
    "# Affichage\n",
    "plt.imshow(downsampled.squeeze(), cmap='gray')\n",
    "plt.title(\"Image downsampled à 7×7\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fd9101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # flatten en 784\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b914c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=root_dir, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=root_dir, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aa4adcb-be17-4f0d-ba9f-4da062227230",
   "metadata": {
    "id": "2v3GqEPU3z0L"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b38b638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "\n",
    "model = LinearModel()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d95744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 0.7088\n",
      "[Epoch 2] Loss: 0.4211\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCH):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12dab41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Test accuracy est de 89.86%\n"
     ]
    }
   ],
   "source": [
    "#test accuracy\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_pred = model(x)\n",
    "        pred = y_pred.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"Le Test accuracy est de {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5becae4-e27f-43ed-a1c5-ced8c16f4cac",
   "metadata": {
    "id": "qeWZ7DeNMG20"
   },
   "source": [
    "## A.2 - Loss and optimizer\n",
    "Create a cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a85b789e",
   "metadata": {
    "id": "a85b789e"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = F.avg_pool2d(x, kernel_size=4)  # [1, 7, 7]\n",
    "    return x.view(-1)                   # [49]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    preprocess\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3681015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=root_dir, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=root_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c6af32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(49, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2159048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=8\n",
    "model = MLP()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc4f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 2.0951\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCH):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96303719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 74.08%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        y_pred = model(x)\n",
    "        pred = y_pred.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"Test accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aec31b-3d2b-4b29-ad85-e88a6e25660a",
   "metadata": {
    "id": "ZCnlsh9iMhx_"
   },
   "source": [
    "## A.3 - Training and testing loops\n",
    "Finally, create the functions `train(model, epoch, preprocess, optimizer)` and `test(model)` to train (one epoch with SGD and a learning rate of $10^{-3}$) and test your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec14563",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=root_dir, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=root_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183060c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),  # [B, 16, 28, 28]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                            # [B, 16, 14, 14]\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),# [B, 32, 14, 14]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                            # [B, 32, 7, 7]\n",
    "            nn.Flatten(),                               # [B, 32*7*7]\n",
    "            nn.Linear(32*7*7, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e5485-b676-4f73-bedc-d35c5fcfd394",
   "metadata": {
    "id": "iMXijrch3z0L"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, preprocess, optimizer):\n",
    "    model.train()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        if preprocess:\n",
    "            x = preprocess(x)\n",
    "\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = y_pred.argmax(dim=1)\n",
    "        total_correct += (pred == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "\n",
    "    train_accuracy = total_correct / total_samples\n",
    "    return optimizer, train_accuracy\n",
    "\n",
    "\n",
    "def test(model, preprocess):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            if preprocess:\n",
    "                x = preprocess(x)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            pred = y_pred.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa359382-2580-44ae-bcdb-3f18cf1f4c61",
   "metadata": {
    "id": "_t4SiXk33z0L"
   },
   "source": [
    "You should get at least 85\\% test accuracy even with only 2 epochs. We will be aiming for around 95\\% test accuracy and above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12bf85-45c6-41d9-87f3-0601bc4b6339",
   "metadata": {
    "id": "nBmfvtl6UbUe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer, train_accuracy = train(model, epoch, preprocess=None, optimizer=optimizer)\n",
    "    test_accuracy = test(model, preprocess=None)\n",
    "\n",
    "    train_acc_list.append(train_accuracy)\n",
    "    test_acc_list.append(test_accuracy)\n",
    "\n",
    "    print(f\"[Epoch {epoch}] Train acc: {train_accuracy:.4f} | Test acc: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "721efa63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_acc_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Jetter un coup d'oeil aux courbes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m plt.plot(\u001b[43mtrain_acc_list\u001b[49m, label=\u001b[33m'\u001b[39m\u001b[33mTrain acc\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m plt.plot(test_acc_list, label=\u001b[33m'\u001b[39m\u001b[33mTest acc\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mEpoch\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_acc_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Jetter un coup d'oeil aux courbes\n",
    "plt.plot(train_acc_list, label='Train acc')\n",
    "plt.plot(test_acc_list, label='Test acc')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy over epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28bb4e-7178-4340-9247-f69591e86dcf",
   "metadata": {
    "id": "RrwYAMMBEUPN"
   },
   "source": [
    "## A.4 - Multi-layer perceptron (MLP)\n",
    "\n",
    "Create a class MLP that creates an MLP of given width and depth, and use it to create a 3-layer MLP of width $100$. We will assume that `width > 0` and `depth > 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb6479-d475-4f0e-b0f7-fdd107d9e835",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8353cd9",
    "outputId": "c7f5eeaf-0638-45c3-842e-4372d21ff712"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, width, depth, input_dim=784, output_dim=10):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # Entrée\n",
    "        layers.append(nn.Linear(input_dim, width))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        # Couches intermédiaires\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        # Sortie\n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdedce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # [1, 28, 28] → [784]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e697a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(width=100, depth=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858172be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # Test\n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            y_pred = model(x)\n",
    "            correct_test += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            total_test += y.size(0)\n",
    "\n",
    "    test_acc = correct_test / total_test\n",
    "    test_acc_list.append(test_acc)\n",
    "\n",
    "    print(f\"[Epoch {epoch}] Train acc: {train_acc:.4f} | Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca5a11-93e4-47ab-81f1-e4ee3cae45c9",
   "metadata": {
    "id": "v1czyC9R3z0R"
   },
   "source": [
    "# A.5 - Deep convolutional model\n",
    "\n",
    "Write a convolutional model, with learned features.\n",
    "Use two layers, one convolutional with 8 filters of size 3x3, then take a relu and max-pool with kernel size 2, and finally flatten and add a Linear layer. You can use the identity as pre-processing function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933e318-5521-4bf8-b011-bdb95ed0d8b0",
   "metadata": {},
   "source": [
    "\n",
    "Here is a little animation to remind you of the sliding window principle of convolutions.\n",
    "\n",
    "![conv](https://github.com//vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c87b30-36d7-4567-b009-a41413afac5b",
   "metadata": {
    "id": "l4QOi_oe3z0R"
   },
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, padding=1),  # [B, 1, 28, 28] → [B, 8, 28, 28]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)                             # [B, 8, 14, 14]\n",
    "        )\n",
    "        self.fc = nn.Linear(8 * 14 * 14, 10)            # Flatten + Linear\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)                                # [B, 8, 14, 14]\n",
    "        x = x.view(x.size(0), -1)                       # [B, 1568]\n",
    "        return self.fc(x)                               # [B, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0313eed-03ad-461d-9ddb-bb690c631149",
   "metadata": {
    "id": "pbQ1LUqf3z0R"
   },
   "source": [
    "You should be able to get around 97\\% to 98\\% accuracy with this model. Try increasing the NUM_EPOCH constant and watch what happens to test accuracy and train accuracy as training progresses further.\n",
    "\n",
    "Write a deeper convolutional model, with one convolutional layer as previously, but three linear layers with relu activations after that.\n",
    "Use `h = 100` hidden neurons. How does the test accuracy compare with the previous two-layer network ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792791e1-0514-4749-a3fb-d27eb10a1bd2",
   "metadata": {
    "id": "YM-OhC123z0R"
   },
   "outputs": [],
   "source": [
    "class DeepConvModel(nn.Module):\n",
    "    def __init__(self, hidden_size=100):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, padding=1),  # [B, 8, 28, 28]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)                             # [B, 8, 14, 14]\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(8 * 14 * 14, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.classifier(x)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "model = DeepConvModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd763b-b36a-461c-ad34-f472e62ce46d",
   "metadata": {},
   "source": [
    "## A.6 Visualisations of convolutions\n",
    "\n",
    "After training your model, let's see what features it has learned!\n",
    "\n",
    "Plot an image from the test set then plot all 8 feature maps extracted by the convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5284c2-4210-4ccc-bf05-5e722bdabf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Récupérer une image du test set\n",
    "image, label = test_dataset[0]\n",
    "image = image.unsqueeze(0)  # [1, 1, 28, 28]\n",
    "\n",
    "# Passer l'image dans la couche convolutionnelle seule\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    feature_maps = model.features(image)  # [1, 8, 14, 14]\n",
    "\n",
    "# Afficher l'image d'origine\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(f\"Original image - label {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Afficher les 8 feature maps\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(feature_maps[0, i].cpu(), cmap='gray')\n",
    "    plt.title(f\"Feature map {i+1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"Feature maps from Conv layer\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc457ad1-3240-4ffb-a8f3-98c6554dfce5",
   "metadata": {
    "id": "riu_K1at3z0R"
   },
   "source": [
    "# Part B - Residual models\n",
    "\n",
    "## B.1 - Residual blocks\n",
    "\n",
    "Write a residual block with two linear layers to learn a function $\\mathbb{R}^d \\to \\mathbb{R}^d$ with $h < d$ hidden neurons.\n",
    "Write a convolutional residual block with the same idea. What hyperparameter acts as the number of hidden neurons in convolutional blocks ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec298d4-4372-4a1f-be53-a278d051c0f6",
   "metadata": {
    "id": "gkCILVwd3z0R"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, d, h):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(d, h),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h, d)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0097d-269c-40f4-b182-bdc79bd5c512",
   "metadata": {
    "id": "huKWOvVc3z0S"
   },
   "source": [
    "## B.2 - Stacking residual blocks\n",
    "\n",
    "Use a single convolution layer, followed by a relu and max-pool, then an arbitrary number of residual blocks as defined above, and finish with a linear layer. Can you match the accuracy of the two-layer network ? Can you exceed it ? What happens when you increase the number of layers ? Look at the details of the ResNet architecture on the lecture's slides to get an idea of how to increase the number of hidden neurons and the number of layers. One of the strengths of ResNets was there relatively low number of parameters compared\n",
    "to a multi-layer architecture like that of the previous section, does this show in your experiments ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d4de4-11e8-490c-8262-064b3e841fa5",
   "metadata": {
    "id": "U4gg9uWg3z0S"
   },
   "outputs": [],
   "source": [
    "class ResidualModel(torch.nn.Module):\n",
    "    def __init__(self, l, h, k=3, out=8):\n",
    "        super(ResidualModel, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(l, h)\n",
    "\n",
    "        self.residual_blocks = nn.Sequential(*[\n",
    "            ResidualBlock(h, h) for _ in range(k)\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(h, out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.residual_blocks(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ca4a6",
   "metadata": {},
   "source": [
    "Exemple d’entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # [1, 28, 28] → [784]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=root_dir, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=root_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62fb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResidualModel(l=784, h=100, k=3, out=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 5\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "    for x, y in train_loader:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    correct_test, total_test = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            y_pred = model(x)\n",
    "            correct_test += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            total_test += y.size(0)\n",
    "\n",
    "    test_acc = correct_test / total_test\n",
    "    test_acc_list.append(test_acc)\n",
    "\n",
    "    print(f\"[Epoch {epoch}] Train acc: {train_acc:.4f} | Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df418703-b1e1-4276-8ba7-dd5622c7b7cd",
   "metadata": {
    "id": "2nes_ZtBoBu0"
   },
   "source": [
    "# Part C - Reimplementing loss functions\n",
    "\n",
    "## C.0 - Combining losses\n",
    "First, we recall that, for a batch of score vectors $s\\in\\mathbb{R}^{n\\times C}$ and true labels $y\\in[1,C]^n$, **cross entropy** is defined as\n",
    "$$CE(s, y) = -\\frac{1}{n}\\sum_{i=1}^n \\log\\left( \\mbox{softmax}(s_i)_{y_i} \\right)$$\n",
    "\n",
    "where $\\mbox{softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_j}}$ is the probability associated to class $i\\in[1,C]$ for a score vector $x\\in\\mathbb{R}^C$.\n",
    "\n",
    "Let's try to compute cross-entropy in three different ways (see the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)):\n",
    "1. Using `nn.CrossEntropyLoss()`.\n",
    "2. Using `nn.NLLLoss()` and `nn.LogSoftmax()`.\n",
    "3. Using `nn.NLLLoss()` and `nn.Softmax()`.\n",
    "\n",
    "Check that the output is the same for all three methods on Gaussian random scores `torch.randn(n_batch, n_classes)` and random labels `torch.randint(0, n_classes, [n_batch])`, where `n_batch=4` and `n_classes=10`. Note that the scores are real valued vectors while the labels are integers corresponding to the true class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6c172",
   "metadata": {
    "id": "e1b6c172"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Paramètres\n",
    "n_batch = 4\n",
    "n_classes = 10\n",
    "\n",
    "# Entrée aléatoire : scores réels + labels entiers\n",
    "s = torch.randn(n_batch, n_classes)            # Scores réels (non normalisés)\n",
    "y = torch.randint(0, n_classes, [n_batch])     # Labels dans [0, 9]\n",
    "\n",
    "# 1. CrossEntropyLoss = LogSoftmax + NLLLoss (automatique)\n",
    "loss1 = nn.CrossEntropyLoss()(s, y)\n",
    "\n",
    "# 2. LogSoftmax + NLLLoss manuels\n",
    "log_softmax = nn.LogSoftmax(dim=1)(s)          # log(probabilités)\n",
    "loss2 = nn.NLLLoss()(log_softmax, y)\n",
    "\n",
    "# 3. Softmax puis log puis NLLLoss — ❌ en pratique incorrect !\n",
    "softmax = nn.Softmax(dim=1)(s)\n",
    "log = torch.log(softmax + 1e-9)                 # ajout epsilon pour éviter log(0)\n",
    "loss3 = nn.NLLLoss()(log, y)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Loss 1 (CrossEntropyLoss)      : {loss1.item():.6f}\")\n",
    "print(f\"Loss 2 (LogSoftmax + NLLLoss)  : {loss2.item():.6f}\")\n",
    "print(f\"Loss 3 (Softmax + log + NLLLoss): {loss3.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba900c6-f7b2-4179-a2f1-f1eede4b6697",
   "metadata": {
    "id": "TWKaTBVd5ftN"
   },
   "source": [
    "## C.1 - Re-implementation\n",
    "Now re-implement cross-entropy using base functions (`torch.log`, `torch.exp`, `torch.sum`, etc...). Verify that your function returns the same value as Pytorch's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EfA-3-E7qwgF",
   "metadata": {
    "id": "EfA-3-E7qwgF"
   },
   "outputs": [],
   "source": [
    "def ce(logits, targets):\n",
    "    # logits : [batch_size, num_classes]\n",
    "    # targets : [batch_size] (entiers 0..C-1)\n",
    "\n",
    "    # 1. softmax sur les classes\n",
    "    softmax = F.softmax(logits, dim=1)  # [B, C]\n",
    "\n",
    "    # 2. récupérer la proba associée à la bonne classe\n",
    "    prob = softmax[torch.arange(len(targets)), targets]  # [B]\n",
    "\n",
    "    # 3. log et moyenne (formule CE)\n",
    "    loss = -torch.log(prob + 1e-9).mean()  # ajout epsilon pour stabilité\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ec13a-330a-4073-99b9-2eb9dd42d1f8",
   "metadata": {
    "id": "OFG0QfKN7WtO"
   },
   "source": [
    "## C.2 - Stability analysis\n",
    "Softmax probabilities can be relatively unstable due to their use of exponentials. Pytorch implementations thus usually use log probas or logits to avoid overflows or floating point errors. Test all methods (including your own) on Gaussian random scores of standard deviation equal to $100$. Which methods are stable? Why? Is it an issue in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741771f5-864d-446a-b654-3b4f5a2598ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données extrêmes\n",
    "n_batch = 4\n",
    "n_classes = 10\n",
    "logits = torch.randn(n_batch, n_classes) * 100  # grande variance\n",
    "targets = torch.randint(0, n_classes, [n_batch])\n",
    "\n",
    "# 1. CrossEntropyLoss (stable)\n",
    "try:\n",
    "    loss1 = nn.CrossEntropyLoss()(logits, targets)\n",
    "    print(f\"[1] CrossEntropyLoss: {loss1.item():.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"[1] CrossEntropyLoss failed: {e}\")\n",
    "\n",
    "# 2. LogSoftmax + NLLLoss (stable)\n",
    "try:\n",
    "    log_probs = F.log_softmax(logits, dim=1)\n",
    "    loss2 = nn.NLLLoss()(log_probs, targets)\n",
    "    print(f\"[2] LogSoftmax + NLLLoss: {loss2.item():.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"[2] LogSoftmax + NLLLoss failed: {e}\")\n",
    "\n",
    "# 3. Softmax + log + NLLLoss (instable)\n",
    "try:\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    log_probs_bad = torch.log(probs + 1e-9)\n",
    "    loss3 = nn.NLLLoss()(log_probs_bad, targets)\n",
    "    print(f\"[3] Softmax + log + NLLLoss: {loss3.item():.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"[3] Softmax + log + NLLLoss failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecaaf7c-b21f-4e18-ac53-1a77adbc60bf",
   "metadata": {
    "id": "Y3y4BfwbBIGy"
   },
   "source": [
    "Re-implement a stable version of cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d00dab-a37e-48da-880f-81f10efdc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_ce(logits, targets):\n",
    "    # logits : [batch_size, num_classes]\n",
    "    # targets : [batch_size]\n",
    "\n",
    "    # Trick : soustraire le max par ligne pour stabiliser les exposants\n",
    "    logits = logits - logits.max(dim=1, keepdim=True).values\n",
    "\n",
    "    # Calcul stable du log-softmax\n",
    "    log_sum_exp = torch.log(torch.sum(torch.exp(logits), dim=1))  # [batch]\n",
    "    log_probs = logits[torch.arange(len(targets)), targets]       # [batch]\n",
    "\n",
    "    # Cross-entropy\n",
    "    loss = -log_probs + log_sum_exp\n",
    "    return loss.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
